{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:11:03.961325Z",
     "start_time": "2024-04-27T10:10:56.863682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Install pytorch for CPU\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Construct the pip install command\n",
    "command = f'\"{sys.executable}\" -m pip install ctransformers>=0.2.24 dlbar'\n",
    "\n",
    "# Execute the command\n",
    "os.system(command)"
   ],
   "id": "85b571bc6d1f5c0b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:11:03.969423Z",
     "start_time": "2024-04-27T10:11:03.963363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "download_url = 'https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/resolve/main/codellama-7b-instruct.Q6_K.gguf?download=true'\n",
    "model_file = 'codellama-7b-instruct.q6_K.gguf'\n",
    "\n",
    "config_url = 'https://huggingface.co/TheBloke/CodeLlama-7B-Instruct-GGUF/blob/main/config.json'\n",
    "\n",
    "# First check if the file already exists\n",
    "if os.path.exists(model_file):\n",
    "    print(f'{model_file} already exists')\n",
    "\n",
    "else:\n",
    "    from dlbar import DownloadBar\n",
    "\n",
    "    download_bar = DownloadBar()\n",
    "\n",
    "    download_bar.download(\n",
    "        url=download_url,\n",
    "        dest=model_file,\n",
    "        title=f'Downloading {model_file}',\n",
    "    )\n",
    "\n",
    "    download_bar.download(\n",
    "        url=config_url,\n",
    "        dest='config.json',\n",
    "        title='Downloading config.json',\n",
    "    )"
   ],
   "id": "8d15775032d9d43c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codellama-7b-instruct.q6_K.gguf already exists\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:14:27.039181Z",
     "start_time": "2024-04-27T10:11:03.971172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "filepath = os.path.join(os.getcwd(), model_file)\n",
    "print('Using model file:', filepath)\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(filepath, model_file=model_file, model_type=\"llama\", gpu_layers=0)\n",
    "\n",
    "print(llm(\"AI is going to\"))"
   ],
   "id": "4c6c9a9a89643373",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model file: /home/lawrencegodfrey/Users/lawrence.godfrey/DataspellProjects/code-assistant/experimentation/codellama-7b-instruct.q6_K.gguf\n",
      " transform how we interact with machines, and it's making humanity better.\n",
      "It's no secret that artificial intelligence (AI) has grown immensely in recent years. It has revolutionized various fields such as healthcare, finance, transportation, and entertainment, among others. In fact, AI is the future of technology, and it has brought significant advancements to humanity.\n",
      "Artificial Intelligence: What is it?\n",
      "Artificial intelligence is a computer system that mimics human intelligence. It uses algorithms to process data, make decisions, recognize patterns, and learn from experience. AI can be divided into sub-categories such as machine learning, deep learning, neural networks, and natural language processing. Each category has its unique aspects with different applications.\n",
      "The History of Artificial Intelligence\n",
      "Artificial intelligence's roots date back to the 1950s when computer scientists like Alan Turing and Marvin Minsky started working on the field of machine intelligence. They developed models that could mimic human intelligence, but they were limited by their inability to generalize. The term \"artificial intelligence\" was introduced later by computer scientist John McCarthy\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:07:37.401998Z",
     "start_time": "2024-04-07T18:06:57.199750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "prompt = 'What is used to host lawrences.tech?'\n",
    "pipe = pipeline(task=\"text-generation\", model=llm, tokenizer=llm.tokenizer)\n",
    "pipe(prompt, max_length=100)"
   ],
   "id": "36c7a333ce231667",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 18:07:13.528169: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-07 18:07:15.939955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-07 18:07:15.940219: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-07 18:07:16.343858: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-07 18:07:17.177632: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-07 18:07:17.189823: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 18:07:25.073723: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LLM' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[1;32m      3\u001B[0m prompt \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWhat is used to host lawrences.tech?\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m pipe \u001B[38;5;241m=\u001B[39m pipeline(task\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mllm, tokenizer\u001B[38;5;241m=\u001B[39m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenizer\u001B[49m)\n\u001B[1;32m      5\u001B[0m pipe(prompt, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/ctransformers/llm.py:321\u001B[0m, in \u001B[0;36mLLM.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mctransformers_llm_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(lib, name):\n\u001B[1;32m    320\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m partial(\u001B[38;5;28mgetattr\u001B[39m(lib, name), llm)\n\u001B[0;32m--> 321\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLLM\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'LLM' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tuning the model on a GitHub repository",
   "id": "cf81c8b83e02b583"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c0842061ebb8e5b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
